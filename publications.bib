@article{duffyVariationSequenceDynamics2019,
  title = {Variation in Sequence Dynamics Improves Maintenance of Stereotyped Behavior in an Example from Bird Song},
  author = {Duffy, Alison and Abe, Elliott and Perkel, David J. and Fairhall, Adrienne L.},
  year = {2019},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {19},
  pages = {9592--9597},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1815910116},
  urldate = {2022-07-10},
  abstract = {Significance             In this work, we show a way by which the nervous system maintains precise, stereotyped behavior in the face of environmental and neural changes. Through a model of bird song learning, we show how instability in neural representation of stable behavior can allow a system to more readily adapt and maintain performance with minimal cost. In this perspective, behaviors are made more robust to environmental change by continually seeking subtly new ways of performing the same task. Thus, one should expect to find variability in neural systems executing stereotyped behaviors, and this variability can serve a constructive role in maintaining skilled behavior.           ,              Performing a stereotyped behavior successfully over time requires both maintaining performance quality and adapting efficiently to environmental or physical changes affecting performance. The bird song system is a paradigmatic example of learning a stereotyped behavior and therefore is a good place to study the interaction of these two goals. Through a model of bird song learning, we show how instability in neural representation of stable behavior confers advantages for adaptation and maintenance with minimal cost to performance quality. A precise, temporally sparse sequence from the premotor nucleus HVC is crucial to the performance of song in songbirds. We find that learning in the presence of sequence variations facilitates rapid relearning after shifts in the target song or muscle structure and results in decreased error with neuron loss. This robustness is due to the prevention of the buildup of correlations in the learned connectivity. In the absence of sequence variations, these correlations grow, due to the relatively low dimensionality of the exploratory variation in comparison with the number of plastic synapses. Our results suggest one would expect to see variability in neural systems executing stereotyped behaviors, and this variability is an advantageous feature rather than a challenge to overcome.},
  copyright = {All rights reserved},
  langid = {english},
  file = {H:\My Drive\Articles\Duffy\duffy_2019_variation_in_sequence_dynamics_improves_maintenance_of_stereotyped_behavior_in.pdf}
}

@article{michaielDynamicsGazeControl2020,
  title = {Dynamics of Gaze Control during Prey Capture in Freely Moving Mice},
  author = {Michaiel, Angie M and Abe, Elliott TT and Niell, Cristopher M},
  editor = {Spering, Miriam and Colgin, Laura L and Isa, Tadashi and Leonardo, Anthony and Churchland, Anne K},
  year = {2020},
  month = jul,
  journal = {eLife},
  volume = {9},
  pages = {e57458},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.57458},
  abstract = {Many studies of visual processing are conducted in constrained conditions such as head- and gaze-fixation, and therefore less is known about how animals actively acquire visual information in natural contexts. To determine how mice target their gaze during natural behavior, we measured head and bilateral eye movements in mice performing prey capture, an ethological behavior that engages vision. We found that the majority of eye movements are compensatory for head movements, thereby serving to stabilize the visual scene. During movement, however, periods of stabilization are interspersed with non-compensatory saccades that abruptly shift gaze position. Notably, these saccades do not preferentially target the prey location. Rather, orienting movements are driven by the head, with the eyes following in coordination to sequentially stabilize and recenter the gaze. These findings relate eye movements in the mouse to other species, and provide a foundation for studying active vision during ethological behaviors in the mouse.},
  copyright = {All rights reserved},
  keywords = {active sensing,ethology,eye movements,mouse,neuroscience,vision},
  file = {H\:\\My Drive\\Articles\\Michaiel\\michaiel_2020_dynamics_of_gaze_control_during_prey_capture_in_freely_moving_mice.pdf;H\:\\My Drive\\Articles\\Michaiel\\michaiel_2020_dynamics_of_gaze_control_during_prey_capture_in_freely_moving_mice2.pdf}
}

@article{parkerDistanceEstimationMonocular2022,
  title = {Distance Estimation from Monocular Cues in an Ethological Visuomotor Task},
  author = {Parker, Philip RL and Abe, Elliott TT and Beatie, Natalie T and Leonard, Emmalyn SP and Martins, Dylan M and Sharp, Shelby L and Wyrick, David G and Mazzucato, Luca and Niell, Cristopher M},
  year = {2022},
  month = sep,
  journal = {eLife},
  volume = {11},
  pages = {e74708},
  issn = {2050-084X},
  doi = {10.7554/eLife.74708},
  urldate = {2022-11-01},
  abstract = {In natural contexts, sensory processing and motor output are closely coupled, which is reflected in the fact that many brain areas contain both sensory and movement signals. However, standard reductionist paradigms decouple sensory decisions from their natural motor consequences, and head-\-fixation prevents the natural sensory consequences of self-m\- otion. In particular, movement through the environment provides a number of depth cues beyond stereo vision that are poorly understood. To study the integration of visual processing and motor output in a naturalistic task, we investigated distance estimation in freely moving mice. We found that mice use vision to accurately jump across a variable gap, thus directly coupling a visual computation to its corresponding ethological motor output. Monocular eyelid suture did not affect gap jumping success, thus mice can use cues that do not depend on binocular disparity and stereo vision. Under monocular conditions, mice altered their head positioning and performed more vertical head movements, consistent with a shift from using stereopsis to other monocular cues, such as motion or position parallax. Finally, optogenetic suppression of primary visual cortex impaired task performance under both binocular and monocular conditions when optical fiber placement was localized to binocular or monocular zone V1, respectively. Together, these results show that mice can use monocular cues, relying on visual cortex, to accurately judge distance. Furthermore, this behavioral paradigm provides a foundation for studying how neural circuits convert sensory information into ethological motor output.},
  copyright = {All rights reserved},
  langid = {english},
  file = {H\:\\My Drive\\Articles\\Parker\\parker_2022_distance_estimation_from_monocular_cues_in_an_ethological_visuomotor_task.pdf;H\:\\My Drive\\Articles\\Parker\\parker_2022_distance_estimation_from_monocular_cues_in_an_ethological_visuomotor_task2.pdf}
}

@article{parkerDynamicSequenceVisual2022,
  title = {A Dynamic Sequence of Visual Processing Initiated by Gaze Shifts},
  author = {Parker, Philip R. L. and Martins, Dylan M. and Leonard, Emmalyn S. P. and Casey, Nathan M. and Sharp, Shelby L. and Abe, Elliott T. T. and Smear, Matthew C. and Yates, Jacob L. and Mitchell, Jude F. and Niell, Cristopher M.},
  year = {2022},
  month = jan,
  journal = {bioRxiv},
  pages = {2022.08.23.504847},
  doi = {10.1101/2022.08.23.504847},
  abstract = {Animals move their head and eyes as they explore and sample the visual scene. Previous studies have demonstrated neural correlates of head and eye movements in rodent primary visual cortex (V1), but the sources and computational roles of these signals are unclear. We addressed this by combining measurement of head and eye movements with high density neural recordings in freely moving mice. V1 neurons responded primarily to gaze shifts, where head movements are accompanied by saccadic eye movements, but not to head movements where compensatory eye movements stabilize gaze. A variety of activity patterns immediately followed gaze shifts, including units with positive, biphasic, or negative responses, and together these responses formed a temporal sequence following the gaze shift. These responses were greatly diminished in the dark for the vast majority of units, replaced by a uniform suppression of activity, and were similar to those evoked by sequentially flashed stimuli in head-fixed conditions, suggesting that gaze shift transients represent the temporal response to the rapid onset of new visual input. Notably, neurons responded in a sequence that matches their spatial frequency preference, from low to high spatial frequency tuning, consistent with coarse-to-fine processing of the visual scene following each gaze shift. Recordings in foveal V1 of freely gazing head-fixed marmosets revealed a similar sequence of temporal response following a saccade, as well as the progression of spatial frequency tuning. Together, our results demonstrate that active vision in both mice and marmosets consists of a dynamic temporal sequence of neural activity associated with visual sampling.HighlightsDuring free movement, neurons in mouse V1 respond to head movements that are accompanied by a gaze-shifting saccadic eye movement, but not a compensatory eye movement.Neurons respond to gaze shifts with diverse temporal dynamics that form a sequence across the population, from early positive responses to biphasic and negative responses.In darkness, most neurons show a uniform suppression following a gaze shift.Temporal dynamics of responses correspond to a neuron's temporal and spatial frequency preferences, consistent with a coarse-to-fine processing sequence.A similar temporal sequence following saccades is observed in foveal V1 of freely gazing head-fixed marmosets, demonstrating shared aspects of active visual processing across species.Competing Interest StatementThe authors have declared no competing interest.},
  copyright = {All rights reserved},
  file = {H:\My Drive\Articles\Parker et al\Parker et al_2022_A dynamic sequence of visual processing initiated by gaze shifts.pdf}
}

@article{parkerDynamicSequenceVisual2023,
  title = {A Dynamic Sequence of Visual Processing Initiated by Gaze Shifts},
  author = {Parker, Philip R. L. and Martins, Dylan M. and Leonard, Emmalyn S. P. and Casey, Nathan M. and Sharp, Shelby L. and Abe, Elliott T. T. and Smear, Matthew C. and Yates, Jacob L. and Mitchell, Jude F. and Niell, Cristopher M.},
  year = {2023},
  month = dec,
  journal = {Nature Neuroscience},
  volume = {26},
  number = {12},
  pages = {2192--2202},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-023-01481-7},
  urldate = {2024-02-01},
  abstract = {Animals move their head and eyes as they explore the visual scene. Neural correlates of these movements have been found in rodent primary visual cortex (V1), but their sources and computational roles are unclear. We addressed this by combining head and eye movement measurements with neural recordings in freely moving mice. V1 neurons responded primarily to gaze shifts, where head movements are accompanied by saccadic eye movements, rather than to head movements where compensatory eye movements stabilize gaze. A variety of activity patterns followed gaze shifts and together these formed a temporal sequence that was absent in darkness. Gaze-shift responses resembled those evoked by sequentially flashed stimuli, suggesting a large component corresponds to onset of new visual input. Notably, neurons responded in a sequence that matches their spatial frequency bias, consistent with coarse-to-fine processing. Recordings in freely gazing marmosets revealed a similar sequence following saccades, also aligned to spatial frequency preference. Our results demonstrate that active vision in both mice and marmosets consists of a dynamic temporal sequence of neural activity associated with visual sampling.},
  copyright = {2023 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Saccades,Sensory processing,Striate cortex},
  file = {H:\My Drive\Articles\Parker et al\Parker et al_2023_A dynamic sequence of visual processing initiated by gaze shifts.pdf}
}

@article{parkerJointCodingVisual2022,
  title = {Joint Coding of Visual Input and {{Eye}}/{{Head}} Position in {{V1}} of Freely Moving Mice},
  author = {Parker, Philip R. L. and Abe, Elliott T. T. and Leonard, Emmalyn S. P. and Martins, Dylan M. and Niell, Cristopher M.},
  year = {2022},
  journal = {Neuron},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2022.08.029},
  abstract = {Visual input during natural behavior is highly dependent on movements of the eyes and head, but how information about eye and head position is integrated with visual processing during free movement is unknown, as visual physiology is generally performed under head fixation. To address this, we performed single-unit electrophysiology in V1 of freely moving mice while simultaneously measuring the mouse's eye position, head orientation, and the visual scene from the mouse's perspective. From these measures, we mapped spatiotemporal receptive fields during free movement based on the gaze-corrected visual input. Furthermore, we found a significant fraction of neurons tuned for eye and head position, and these signals were integrated with visual responses through a multiplicative mechanism in the majority of modulated neurons. These results provide new insight into coding in the mouse V1 and, more generally, provide a paradigm for investigating visual physiology under natural conditions, including active sensing and ethological behavior.},
  copyright = {All rights reserved},
  keywords = {ecological perception,gain modulation,receptive fields,visual cortex,visual physiology},
  file = {H:\My Drive\Articles\Parker\parker_abe_2022_joint_coding_of_visual_input_and_eye-head_position_in_v1_of_freely_moving_mice.pdf}
}
