---
title: "Joint Coding of Visual Input and Eye/Head Position in V1 of Freely Moving Mice"
summary: In this project, we (1) developed a method for freely moving visual physiology, (2) measured the first freely-moving visual receptive fields, (3) found V1 neurons are tuned to eye position and head orientation, and (4) showed visual input and eye/head position predominately integrate through multiplicative gain modulation 
tags:
  - Visual encoding
  - Gain modulation
  - Ethological behavior
date: "2022-09-29T00:00:00Z"

# Optional external URL for project (replaces project detail page).
external_link: ''

image:
  caption: Graphic created by Anne Martin Ph.D.
  focal_point: Smart

links:
  - icon: github
    icon_pack: fab
    name: pytorchGLM
    url: https://github.com/elliottabe/pytorchGLM
url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''
---
Visual input during natural behavior is highly dependent on movements of the eyes and head, but how information about eye and head position is integrated with visual processing during free movement is unknown, as visual physiology is generally performed under head fixation. To address this, we performed single-unit electrophysiology in V1 of freely moving mice while simultaneously measuring the mouse's eye position, head orientation, and the visual scene from the mouse's perspective. From these measures, we mapped spatiotemporal receptive fields during free movement based on the gaze-corrected visual input. Furthermore, we found a significant fraction of neurons tuned for eye and head position, and these signals were integrated with visual responses through a multiplicative mechanism in the majority of modulated neurons. These results provide new insight into coding in the mouse V1 and, more generally, provide a paradigm for investigating visual physiology under natural conditions, including active sensing and ethological behavior.