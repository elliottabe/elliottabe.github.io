---
title: "Joint Coding of Visual Input and Eye/Head Position in V1 of Freely Moving Mice"
summary: A key feature of TiDHy is that it directly learns the intrinsic timescales of the data (rather than as a hyperparameter) and demixes independent systems, yielding interpretable dynamics. Using synthetic data, we show that TiDHy can demix multiple SLDSs from partially superimposed observations, even when they span orders-of-magnitude different timescales.
tags:
  - Visual encoding
  - Gain modulation
  - Ethological behavior
date: "2022-09-29T00:00:00Z"

# Optional external URL for project (replaces project detail page).
external_link: ''

image:
  caption: Graphic created by Anne Martin Ph.D.
  focal_point: Smart

links:
  - icon: github
    icon_pack: fab
    name: TiDHy
url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''
---
Visual input during natural behavior is highly dependent on movements of the eyes and head, but how information about eye and head position is integrated with visual processing during free movement is unknown, as visual physiology is generally performed under head fixation. To address this, we performed single-unit electrophysiology in V1 of freely moving mice while simultaneously measuring the mouse's eye position, head orientation, and the visual scene from the mouse's perspective. From these measures, we mapped spatiotemporal receptive fields during free movement based on the gaze-corrected visual input. Furthermore, we found a significant fraction of neurons tuned for eye and head position, and these signals were integrated with visual responses through a multiplicative mechanism in the majority of modulated neurons. These results provide new insight into coding in the mouse V1 and, more generally, provide a paradigm for investigating visual physiology under natural conditions, including active sensing and ethological behavior.